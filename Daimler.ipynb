{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Daimler.ipynb","provenance":[],"authorship_tag":"ABX9TyOa8asltqGRMYAtCJKYhtt5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bkcoGa3yyogU","executionInfo":{"status":"ok","timestamp":1605794180381,"user_tz":-330,"elapsed":6748,"user":{"displayName":"SHRISHA HEGDE","photoUrl":"","userId":"15195555852924790477"}},"outputId":"3775d0e5-be1c-45bd-c488-43c79585ca51"},"source":["# Step1: Import the required libraries\n","\n","# linear algebra\n","import numpy as np\n","# data processing, CSV file I/O (e.g. pd.read_csv)\n","import pandas as pd\n","# for dimensionality reduction\n","from sklearn.decomposition import PCA\n","\n","# Step2: Read the data from train.csv\n","\n","df_train = pd.read_csv('train.csv')\n","# let us understand the data\n","print('Size of training set: {} rows and {} columns'\n","      .format(*df_train.shape))\n","# print few rows and see how the data looks like\n","df_train.head()\n","\n","# Step3: Collect the Y values into an array\n","\n","# seperate the y from the data as we will use this to learn as \n","# the prediction output\n","y_train = df_train['y'].values\n","\n","# Step4: Understand the data types we have\n","\n","# iterate through all the columns which has X in the name of the column\n","cols = [c for c in df_train.columns if 'X' in c]\n","print('Number of features: {}'.format(len(cols)))\n","\n","print('Feature types:')\n","df_train[cols].dtypes.value_counts()\n","\n","# Step5: Count the data in each of the columns\n","\n","counts = [[], [], []]\n","for c in cols:\n","    typ = df_train[c].dtype\n","    uniq = len(np.unique(df_train[c]))\n","    if uniq == 1:\n","        counts[0].append(c)\n","    elif uniq == 2 and typ == np.int64:\n","        counts[1].append(c)\n","    else:\n","        counts[2].append(c)\n","\n","print('Constant features: {} Binary features: {} Categorical features: {}\\n'\n","      .format(*[len(c) for c in counts]))\n","print('Constant features:', counts[0])\n","print('Categorical features:', counts[2])\n","\n","# Step6: Read the test.csv data\n","\n","df_test = pd.read_csv('test.csv')\n","\n","# remove columns ID and Y from the data as they are not used for learning\n","usable_columns = list(set(df_train.columns) - set(['ID', 'y']))\n","y_train = df_train['y'].values\n","id_test = df_test['ID'].values\n","\n","x_train = df_train[usable_columns]\n","x_test = df_test[usable_columns]\n","\n","# Step7: Check for null and unique values for test and train sets\n","\n","def check_missing_values(df):\n","    if df.isnull().any().any():\n","        print(\"There are missing values in the dataframe\")\n","    else:\n","        print(\"There are no missing values in the dataframe\")\n","check_missing_values(x_train)\n","check_missing_values(x_test)\n","\n","# Step8: If for any column(s), the variance is equal to zero, \n","# then you need to remove those variable(s).\n","# Apply label encoder\n","\n","for column in usable_columns:\n","    cardinality = len(np.unique(x_train[column]))\n","    if cardinality == 1:\n","        x_train.drop(column, axis=1) # Column with only one \n","        # value is useless so we drop it\n","        x_test.drop(column, axis=1)\n","    if cardinality > 2: # Column is categorical\n","        mapper = lambda x: sum([ord(digit) for digit in x])\n","        x_train[column] = x_train[column].apply(mapper)\n","        x_test[column] = x_test[column].apply(mapper)\n","x_train.head()\n","\n","# Step9: Make sure the data is now changed into numericals\n","\n","print('Feature types:')\n","x_train[cols].dtypes.value_counts()\n","\n","# Step10: Perform dimensionality reduction\n","# Linear dimensionality reduction using Singular Value Decomposition of \n","# the data to project it to a lower dimensional space.\n","n_comp = 12\n","pca = PCA(n_components=n_comp, random_state=420)\n","pca2_results_train = pca.fit_transform(x_train)\n","pca2_results_test = pca.transform(x_test)\n","\n","# Step11: Training using xgboost\n","\n","import xgboost as xgb\n","from sklearn.metrics import r2_score\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_valid, y_train, y_valid = train_test_split(\n","        pca2_results_train, \n","        y_train, test_size=0.2, \n","        random_state=4242)\n","\n","d_train = xgb.DMatrix(x_train, label=y_train)\n","d_valid = xgb.DMatrix(x_valid, label=y_valid)\n","#d_test = xgb.DMatrix(x_test)\n","d_test = xgb.DMatrix(pca2_results_test)\n","\n","params = {}\n","params['objective'] = 'reg:linear'\n","params['eta'] = 0.02\n","params['max_depth'] = 4\n","\n","def xgb_r2_score(preds, dtrain):\n","    labels = dtrain.get_label()\n","    return 'r2', r2_score(labels, preds)\n","\n","watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n","\n","clf = xgb.train(params, d_train, \n","                1000, watchlist, early_stopping_rounds=50, \n","                feval=xgb_r2_score, maximize=True, verbose_eval=10)\n","\n","# Step12: Predict your test_df values using xgboost\n","\n","p_test = clf.predict(d_test)\n","\n","sub = pd.DataFrame()\n","sub['ID'] = id_test\n","sub['y'] = p_test\n","sub.to_csv('xgb.csv', index=False)\n","\n","sub.head()"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Size of training set: 4209 rows and 378 columns\n","Number of features: 376\n","Feature types:\n","Constant features: 12 Binary features: 356 Categorical features: 8\n","\n","Constant features: ['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293', 'X297', 'X330', 'X347']\n","Categorical features: ['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']\n","There are no missing values in the dataframe\n","There are no missing values in the dataframe\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["Feature types:\n","[13:56:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[0]\ttrain-rmse:99.1484\tvalid-rmse:98.263\ttrain-r2:-58.353\tvalid-r2:-67.6375\n","Multiple eval metrics have been passed: 'valid-r2' will be used for early stopping.\n","\n","Will train until valid-r2 hasn't improved in 50 rounds.\n","[10]\ttrain-rmse:81.2766\tvalid-rmse:80.3643\ttrain-r2:-38.8843\tvalid-r2:-44.9101\n","[20]\ttrain-rmse:66.7161\tvalid-rmse:65.7733\ttrain-r2:-25.874\tvalid-r2:-29.7526\n","[30]\ttrain-rmse:54.8691\tvalid-rmse:53.8914\ttrain-r2:-17.1772\tvalid-r2:-19.6453\n","[40]\ttrain-rmse:45.2471\tvalid-rmse:44.2232\ttrain-r2:-11.361\tvalid-r2:-12.9022\n","[50]\ttrain-rmse:37.4485\tvalid-rmse:36.3763\ttrain-r2:-7.46723\tvalid-r2:-8.4063\n","[60]\ttrain-rmse:31.1458\tvalid-rmse:30.0227\ttrain-r2:-4.85694\tvalid-r2:-5.40739\n","[70]\ttrain-rmse:26.0841\tvalid-rmse:24.9151\ttrain-r2:-3.10794\tvalid-r2:-3.41272\n","[80]\ttrain-rmse:22.0431\tvalid-rmse:20.8306\ttrain-r2:-1.93371\tvalid-r2:-2.08452\n","[90]\ttrain-rmse:18.8467\tvalid-rmse:17.5961\ttrain-r2:-1.14457\tvalid-r2:-1.20096\n","[100]\ttrain-rmse:16.3329\tvalid-rmse:15.079\ttrain-r2:-0.610646\tvalid-r2:-0.616328\n","[110]\ttrain-rmse:14.3978\tvalid-rmse:13.1472\ttrain-r2:-0.251603\tvalid-r2:-0.228703\n","[120]\ttrain-rmse:12.9294\tvalid-rmse:11.6932\ttrain-r2:-0.009312\tvalid-r2:0.028034\n","[130]\ttrain-rmse:11.8128\tvalid-rmse:10.6145\ttrain-r2:0.157486\tvalid-r2:0.199101\n","[140]\ttrain-rmse:10.9879\tvalid-rmse:9.85803\ttrain-r2:0.27105\tvalid-r2:0.309185\n","[150]\ttrain-rmse:10.383\tvalid-rmse:9.32163\ttrain-r2:0.349095\tvalid-r2:0.382317\n","[160]\ttrain-rmse:9.92744\tvalid-rmse:8.95981\ttrain-r2:0.40496\tvalid-r2:0.429337\n","[170]\ttrain-rmse:9.59287\tvalid-rmse:8.71174\ttrain-r2:0.444393\tvalid-r2:0.4605\n","[180]\ttrain-rmse:9.35054\tvalid-rmse:8.55235\ttrain-r2:0.472108\tvalid-r2:0.480061\n","[190]\ttrain-rmse:9.16464\tvalid-rmse:8.44712\ttrain-r2:0.49289\tvalid-r2:0.492776\n","[200]\ttrain-rmse:9.0202\tvalid-rmse:8.38462\ttrain-r2:0.508749\tvalid-r2:0.500254\n","[210]\ttrain-rmse:8.91555\tvalid-rmse:8.34397\ttrain-r2:0.520081\tvalid-r2:0.505088\n","[220]\ttrain-rmse:8.83633\tvalid-rmse:8.32316\ttrain-r2:0.528572\tvalid-r2:0.507554\n","[230]\ttrain-rmse:8.77005\tvalid-rmse:8.30761\ttrain-r2:0.535618\tvalid-r2:0.509393\n","[240]\ttrain-rmse:8.71594\tvalid-rmse:8.3018\ttrain-r2:0.541331\tvalid-r2:0.510078\n","[250]\ttrain-rmse:8.66988\tvalid-rmse:8.29237\ttrain-r2:0.546165\tvalid-r2:0.511191\n","[260]\ttrain-rmse:8.63467\tvalid-rmse:8.2907\ttrain-r2:0.549844\tvalid-r2:0.511388\n","[270]\ttrain-rmse:8.6027\tvalid-rmse:8.28735\ttrain-r2:0.553172\tvalid-r2:0.511783\n","[280]\ttrain-rmse:8.57242\tvalid-rmse:8.29063\ttrain-r2:0.556311\tvalid-r2:0.511396\n","[290]\ttrain-rmse:8.54511\tvalid-rmse:8.28924\ttrain-r2:0.559133\tvalid-r2:0.51156\n","[300]\ttrain-rmse:8.51604\tvalid-rmse:8.28712\ttrain-r2:0.562128\tvalid-r2:0.51181\n","[310]\ttrain-rmse:8.48998\tvalid-rmse:8.28592\ttrain-r2:0.564804\tvalid-r2:0.511951\n","[320]\ttrain-rmse:8.46106\tvalid-rmse:8.28617\ttrain-r2:0.567764\tvalid-r2:0.511922\n","[330]\ttrain-rmse:8.4415\tvalid-rmse:8.28464\ttrain-r2:0.56976\tvalid-r2:0.512102\n","[340]\ttrain-rmse:8.4195\tvalid-rmse:8.28645\ttrain-r2:0.571999\tvalid-r2:0.511889\n","[350]\ttrain-rmse:8.39341\tvalid-rmse:8.28241\ttrain-r2:0.574648\tvalid-r2:0.512364\n","[360]\ttrain-rmse:8.37088\tvalid-rmse:8.27969\ttrain-r2:0.576929\tvalid-r2:0.512685\n","[370]\ttrain-rmse:8.34114\tvalid-rmse:8.27442\ttrain-r2:0.579929\tvalid-r2:0.513305\n","[380]\ttrain-rmse:8.31562\tvalid-rmse:8.27152\ttrain-r2:0.582496\tvalid-r2:0.513646\n","[390]\ttrain-rmse:8.28928\tvalid-rmse:8.26935\ttrain-r2:0.585137\tvalid-r2:0.513901\n","[400]\ttrain-rmse:8.26666\tvalid-rmse:8.26671\ttrain-r2:0.587398\tvalid-r2:0.514211\n","[410]\ttrain-rmse:8.2439\tvalid-rmse:8.26288\ttrain-r2:0.589666\tvalid-r2:0.514661\n","[420]\ttrain-rmse:8.21555\tvalid-rmse:8.26016\ttrain-r2:0.592484\tvalid-r2:0.514981\n","[430]\ttrain-rmse:8.19303\tvalid-rmse:8.26031\ttrain-r2:0.594715\tvalid-r2:0.514963\n","[440]\ttrain-rmse:8.17164\tvalid-rmse:8.25977\ttrain-r2:0.596829\tvalid-r2:0.515026\n","[450]\ttrain-rmse:8.14218\tvalid-rmse:8.2599\ttrain-r2:0.59973\tvalid-r2:0.515012\n","[460]\ttrain-rmse:8.1226\tvalid-rmse:8.25914\ttrain-r2:0.601653\tvalid-r2:0.5151\n","[470]\ttrain-rmse:8.10366\tvalid-rmse:8.25797\ttrain-r2:0.603508\tvalid-r2:0.515238\n","[480]\ttrain-rmse:8.0763\tvalid-rmse:8.25815\ttrain-r2:0.606181\tvalid-r2:0.515217\n","[490]\ttrain-rmse:8.04637\tvalid-rmse:8.25693\ttrain-r2:0.609095\tvalid-r2:0.515361\n","[500]\ttrain-rmse:8.01612\tvalid-rmse:8.25679\ttrain-r2:0.612029\tvalid-r2:0.515376\n","[510]\ttrain-rmse:7.99316\tvalid-rmse:8.25607\ttrain-r2:0.614248\tvalid-r2:0.515461\n","[520]\ttrain-rmse:7.97313\tvalid-rmse:8.25608\ttrain-r2:0.616179\tvalid-r2:0.51546\n","[530]\ttrain-rmse:7.95338\tvalid-rmse:8.25576\ttrain-r2:0.618078\tvalid-r2:0.515498\n","[540]\ttrain-rmse:7.93053\tvalid-rmse:8.25693\ttrain-r2:0.620269\tvalid-r2:0.515361\n","[550]\ttrain-rmse:7.90791\tvalid-rmse:8.25642\ttrain-r2:0.622432\tvalid-r2:0.51542\n","[560]\ttrain-rmse:7.88661\tvalid-rmse:8.25829\ttrain-r2:0.624463\tvalid-r2:0.515201\n","[570]\ttrain-rmse:7.86716\tvalid-rmse:8.25876\ttrain-r2:0.626313\tvalid-r2:0.515146\n","[580]\ttrain-rmse:7.84482\tvalid-rmse:8.26194\ttrain-r2:0.628433\tvalid-r2:0.514772\n","Stopping. Best iteration:\n","[533]\ttrain-rmse:7.94396\tvalid-rmse:8.25522\ttrain-r2:0.618982\tvalid-r2:0.515561\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>83.212578</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>97.355774</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>83.031235</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>76.931931</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>112.632545</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID           y\n","0   1   83.212578\n","1   2   97.355774\n","2   3   83.031235\n","3   4   76.931931\n","4   5  112.632545"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"oRg7Ny4_ypKN"},"source":[""],"execution_count":null,"outputs":[]}]}